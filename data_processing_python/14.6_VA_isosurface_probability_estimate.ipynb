{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52f2b394-2c44-4d9b-909f-71b6f8523185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/128]\n",
      "[32/128]\n",
      "[48/128]\n",
      "[64/128]\n",
      "[80/128]\n",
      "[96/128]\n",
      "[112/128]\n",
      "[128/128]\n",
      "prob range: min=0.000, max=1.000\n",
      "âœ“ Saved data/green_monkey/va_testing/out_latent_occ/latent_occ_p60.glb  (faces=125768)\n",
      "âœ“ Saved data/green_monkey/va_testing/out_latent_occ/latent_occ_p80.glb  (faces=91248)\n",
      "âœ“ Saved data/green_monkey/va_testing/out_latent_occ/latent_occ_p95.glb  (faces=53194)\n",
      "âœ“ Saved layered GLB: data/green_monkey/va_testing/out_latent_occ/latent_occ_all.glb\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# === Latent Occupancy Field: Bootstrap Metaballs â†’ Probability Isosurfaces (GLB) ===\n",
    "# Requirements: numpy, pandas, scipy, scikit-image, trimesh\n",
    "# Input: CSV with columns ['middle_x','middle_y','middle_z'] (or provide a DataFrame)\n",
    "# Usage:\n",
    "#   1) Set csv_path below (or pass df directly to run_latent_occupancy(df=...))\n",
    "#   2) Run. GLBs will appear in out_latent_occ/.\n",
    "# Notes:\n",
    "#   - Tune n_boot / sample_frac / grid_base / sigma_vox / metaball_level for your data & speed.\n",
    "#   - If 95% surface is empty, reduce prob_levels or increase n_boot.\n",
    "\n",
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage.measure import marching_cubes\n",
    "import trimesh\n",
    "\n",
    "# -------------------------- USER SETTINGS --------------------------\n",
    "csv_path      = \"data/green_monkey/all_structure_files/chr1/12hrs/vacv/structure_12hrs_vacv_gene_info.csv\"\n",
    "out_dir       = \"data/green_monkey/va_testing/out_latent_occ\"\n",
    "np.random.seed(7)\n",
    "\n",
    "# Bootstrap + field settings\n",
    "# n_boot          = 64          # â†‘ for smoother probabilities (e.g., 128â€“256). 64 is quick-ish.\n",
    "# sample_frac     = 0.8         # fraction of genes per bootstrap (with replacement)\n",
    "# grid_base       = 128         # longest grid dimension (others scale by aspect). 160â€“192 if you have RAM.\n",
    "# sigma_vox       = 2.0         # Gaussian blur in *voxels* (metaball smoothing)\n",
    "# metaball_level  = 0.15        # iso on each smoothed field, as fraction of that field's max (0.10â€“0.25 typical)\n",
    "# prob_levels     = [0.60, 0.80, 0.95]  # probability isosurfaces to export\n",
    "# min_points      = 50          # safety: require at least this many points\n",
    "\n",
    "n_boot         = 128        # smoother probabilities\n",
    "sample_frac    = 0.90       # keep more genes per resample\n",
    "grid_base      = 160        # finer grid reduces aliasing (watch RAM)\n",
    "sigma_vox      = 3.0        # thicker local support â†’ continuous lobes\n",
    "metaball_level = 0.10       # ignored when thr_mode='quantile'\n",
    "prob_levels    = [0.60, 0.80, 0.95]  # add 50% so you can see where occupancy starts\n",
    "min_points      = 50          # safety: require at least this many points\n",
    "\n",
    "\n",
    "# -------------------------- HELPERS --------------------------\n",
    "def load_points(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    cols = [\"middle_x\",\"middle_y\",\"middle_z\"]\n",
    "    if not all(c in df.columns for c in cols):\n",
    "        raise ValueError(f\"CSV must contain columns {cols}\")\n",
    "    pts = df[cols].dropna().values.astype(np.float32)\n",
    "    return pts\n",
    "\n",
    "def make_grid_from_bounds(pts, base=128, pad_frac=0.05):\n",
    "    mins = pts.min(axis=0)\n",
    "    maxs = pts.max(axis=0)\n",
    "    ext  = maxs - mins\n",
    "    pad  = pad_frac * float(ext.max())\n",
    "    mins2 = mins - pad\n",
    "    maxs2 = maxs + pad\n",
    "    ext2  = maxs2 - mins2\n",
    "    # proportional grid with longest axis == base\n",
    "    scale = base / float(ext2.max() + 1e-8)\n",
    "    dims  = np.ceil(ext2 * scale).astype(int)\n",
    "    dims  = np.clip(dims, 32, 512)  # sanity bounds\n",
    "    # histogramdd expects X,Y,Z ordering\n",
    "    x_edges = np.linspace(mins2[0], maxs2[0], dims[0] + 1, dtype=np.float32)\n",
    "    y_edges = np.linspace(mins2[1], maxs2[1], dims[1] + 1, dtype=np.float32)\n",
    "    z_edges = np.linspace(mins2[2], maxs2[2], dims[2] + 1, dtype=np.float32)\n",
    "    # voxel sizes\n",
    "    vx = np.diff(x_edges)[0]; vy = np.diff(y_edges)[0]; vz = np.diff(z_edges)[0]\n",
    "    origin_xyz = np.array([x_edges[0] + 0.5*vx, y_edges[0] + 0.5*vy, z_edges[0] + 0.5*vz], dtype=np.float32)\n",
    "    return (x_edges, y_edges, z_edges), (vx, vy, vz), origin_xyz, dims\n",
    "\n",
    "# def one_boot_mask(sample_pts, edges, sigma_vox, metaball_level):\n",
    "#     # Histogram in X,Y,Z\n",
    "#     H, _edges = np.histogramdd(sample_pts, bins=edges)  # returns (H, [x_edges,y_edges,z_edges])\n",
    "#     H = H.astype(np.float32, copy=False)\n",
    "\n",
    "#     # Gaussian smooth (metaball effect)\n",
    "#     F = gaussian_filter(H, sigma=(sigma_vox, sigma_vox, sigma_vox), mode=\"constant\")\n",
    "#     F = F.astype(np.float32, copy=False)\n",
    "\n",
    "#     thr = float(F.max()) * float(metaball_level)\n",
    "#     if thr <= 0:\n",
    "#         return None\n",
    "\n",
    "#     mask_xyz = (F >= thr)\n",
    "\n",
    "#     # Convert to Z,Y,X for marching_cubes compatibility later\n",
    "#     mask_zyx = mask_xyz.transpose(2, 1, 0)\n",
    "#     return mask_zyx\n",
    "\n",
    "from scipy.ndimage import gaussian_filter, label\n",
    "\n",
    "def one_boot_mask(sample_pts, edges, sigma_vox, metaball_level=None,\n",
    "                  thr_mode=\"quantile\", metaball_q=0.90, min_blob_vox=40):\n",
    "    \"\"\"\n",
    "    Build a binary metaball mask for one bootstrap:\n",
    "      - Smooths voxelized points (sigma_vox)\n",
    "      - Thresholds by quantile (top (1-q) of field) or relative max\n",
    "      - Drops tiny specks (< min_blob_vox voxels)\n",
    "    \"\"\"\n",
    "    H, _ = np.histogramdd(sample_pts, bins=edges)\n",
    "    H = H.astype(np.float32)\n",
    "\n",
    "    F = gaussian_filter(H, sigma=(sigma_vox, sigma_vox, sigma_vox), mode=\"constant\")\n",
    "    F = F.astype(np.float32)\n",
    "\n",
    "    if thr_mode == \"quantile\":\n",
    "        vals = F[F > 0]\n",
    "        if vals.size == 0:\n",
    "            return None\n",
    "        thr = float(np.quantile(vals, metaball_q))  # e.g., q=0.90 keeps top 10% of positive field\n",
    "    else:  # \"relative_max\"\n",
    "        use_level = 0.10 if metaball_level is None else metaball_level\n",
    "        thr = float(F.max()) * float(use_level)\n",
    "\n",
    "    if thr <= 0:\n",
    "        return None\n",
    "\n",
    "    mask_xyz = (F >= thr)\n",
    "\n",
    "    # # de-speckle\n",
    "    # lbl, nlab = label(mask_xyz)\n",
    "    # if nlab > 0:\n",
    "    #     sizes = np.bincount(lbl.ravel())\n",
    "    #     keep_ids = np.where(sizes >= max(1, int(min_blob_vox)))[0]\n",
    "    #     mask_xyz = np.isin(lbl, keep_ids)\n",
    "    # de-speckle\n",
    "    lbl, nlab = label(mask_xyz)\n",
    "    if nlab > 0:\n",
    "        sizes = np.bincount(lbl.ravel())\n",
    "        # EXCLUDE background label 0\n",
    "        keep_ids = np.where((np.arange(len(sizes)) > 0) & (sizes >= max(1, int(min_blob_vox))))[0]\n",
    "        mask_xyz = np.isin(lbl, keep_ids)\n",
    "\n",
    "    # convert to Z,Y,X for marching_cubes later\n",
    "    return mask_xyz.transpose(2, 1, 0)\n",
    "\n",
    "\n",
    "# def prob_isosurface(prob_zyx, level, spacing_zyx, origin_xyz):\n",
    "#     if not (0.0 < level < 1.0):\n",
    "#         return None\n",
    "#     if (prob_zyx >= level).sum() == 0:\n",
    "#         return None\n",
    "#     verts_zyx, faces, _, _ = marching_cubes(prob_zyx, level=level, spacing=spacing_zyx)\n",
    "#     # reorder to X,Y,Z and translate to world coords\n",
    "#     verts_xyz = np.c_[verts_zyx[:,2], verts_zyx[:,1], verts_zyx[:,0]].astype(np.float32)\n",
    "#     verts_xyz += origin_xyz  # shift to real-world coordinate system\n",
    "#     mesh = trimesh.Trimesh(vertices=verts_xyz, faces=faces, process=False)\n",
    "#     return mesh\n",
    "\n",
    "def prob_isosurface(prob_zyx, level, spacing_zyx, origin_xyz, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Safe wrapper: if level is outside the actual data range, or if the\n",
    "    surface is degenerate, return None.\n",
    "    \"\"\"\n",
    "    # Ignore NaNs in range checks\n",
    "    vmin = float(np.nanmin(prob_zyx))\n",
    "    vmax = float(np.nanmax(prob_zyx))\n",
    "    if not (vmin < level < vmax):   # must be strictly inside range\n",
    "        return None\n",
    "\n",
    "    # Must have both sides of the isovalue present somewhere\n",
    "    ge = np.count_nonzero(prob_zyx >= level)\n",
    "    lt = np.count_nonzero(prob_zyx <  level)\n",
    "    if ge == 0 or lt == 0:\n",
    "        return None\n",
    "\n",
    "    # Nudge level away from exact plateaus\n",
    "    lvl = float(np.clip(level, vmin + eps, vmax - eps))\n",
    "\n",
    "    try:\n",
    "        verts_zyx, faces, _, _ = marching_cubes(prob_zyx, level=lvl, spacing=spacing_zyx)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "    if faces.size == 0:\n",
    "        return None\n",
    "\n",
    "    # reorder to X,Y,Z and translate to world coords\n",
    "    verts_xyz = np.c_[verts_zyx[:,2], verts_zyx[:,1], verts_zyx[:,0]].astype(np.float32)\n",
    "    verts_xyz += origin_xyz\n",
    "    return trimesh.Trimesh(vertices=verts_xyz, faces=faces, process=False)\n",
    "\n",
    "\n",
    "def ensure_outdir(path):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# -------------------------- MAIN --------------------------\n",
    "def run_latent_occupancy(csv=None, df=None):\n",
    "    ensure_outdir(out_dir)\n",
    "\n",
    "    # ---- load points ----\n",
    "    if df is None and csv is None:\n",
    "        raise ValueError(\"Provide csv=path or df=DataFrame.\")\n",
    "    pts = load_points(csv) if df is None else df[[\"middle_x\",\"middle_y\",\"middle_z\"]].dropna().values.astype(np.float32)\n",
    "    n = len(pts)\n",
    "    if n < min_points:\n",
    "        raise ValueError(f\"Too few points ({n}). Need at least {min_points}.\")\n",
    "\n",
    "    # ---- grid ----\n",
    "    edges, voxel_xyz, origin_xyz, dims_xyz = make_grid_from_bounds(pts, base=grid_base, pad_frac=0.05)\n",
    "    x_edges, y_edges, z_edges = edges\n",
    "    vx, vy, vz = voxel_xyz\n",
    "    spacing_zyx = (vz, vy, vx)  # marching_cubes spacing order\n",
    "\n",
    "    # ---- bootstrap occupancy count (Z,Y,X layout) ----\n",
    "    occ_count = np.zeros((len(z_edges)-1, len(y_edges)-1, len(x_edges)-1), dtype=np.uint16)\n",
    "    boot_k = max(1, int(round(sample_frac * n)))\n",
    "\n",
    "    for b in range(n_boot):\n",
    "        idx = np.random.choice(n, size=boot_k, replace=True)\n",
    "        sample_pts = pts[idx]\n",
    "        # mask_zyx = one_boot_mask(sample_pts, edges, sigma_vox=sigma_vox, metaball_level=metaball_level)\n",
    "        mask_zyx = one_boot_mask(\n",
    "            sample_pts, edges,\n",
    "            sigma_vox=sigma_vox,\n",
    "            metaball_level=metaball_level,   # still passed for fallback\n",
    "            thr_mode=\"quantile\",\n",
    "            metaball_q=0.90,                 # try 0.88â€“0.92 if you need to tune\n",
    "            min_blob_vox=40                  # raise to 80 if you want fewer small islands\n",
    "        )\n",
    "\n",
    "        if mask_zyx is None:\n",
    "            continue\n",
    "        occ_count += mask_zyx.astype(np.uint16)\n",
    "        if (b+1) % max(1, n_boot//8) == 0:\n",
    "            print(f\"[{b+1}/{n_boot}]\")\n",
    "\n",
    "    # ---- probability field ----\n",
    "    prob_zyx = (occ_count.astype(np.float32) / float(n_boot)).astype(np.float32)\n",
    "    print(f\"prob range: min={np.nanmin(prob_zyx):.3f}, max={np.nanmax(prob_zyx):.3f}\")\n",
    "\n",
    "    # ---- save volume & metadata ----\n",
    "    np.save(os.path.join(out_dir, \"latent_occ_prob.npy\"), prob_zyx)\n",
    "    meta = {\n",
    "        \"origin_xyz\": origin_xyz.tolist(),\n",
    "        \"voxel_xyz\": [float(vx), float(vy), float(vz)],\n",
    "        \"shape_zyx\": list(map(int, prob_zyx.shape)),\n",
    "        \"n_boot\": n_boot,\n",
    "        \"sample_frac\": sample_frac,\n",
    "        \"grid_base\": grid_base,\n",
    "        \"sigma_vox\": sigma_vox,\n",
    "        \"metaball_level\": metaball_level,\n",
    "        \"prob_levels\": prob_levels\n",
    "    }\n",
    "    with open(os.path.join(out_dir, \"latent_occ_meta.json\"), \"w\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "\n",
    "    # ---- extract and export isosurfaces ----\n",
    "    meshes = []\n",
    "    colors = {\n",
    "        0.60: [180,180,180,255],  # 60% light gray: speculative\n",
    "        0.80: [120,120,220,255],  # 80% bluish: consistent\n",
    "        0.95: [240,180,60,255],   # 95% gold: very stable core\n",
    "    }\n",
    "    label_map = {0.60:\"p60\", 0.80:\"p80\", 0.95:\"p95\"}\n",
    "\n",
    "    for lvl in prob_levels:\n",
    "        m = prob_isosurface(prob_zyx, level=float(lvl), spacing_zyx=spacing_zyx, origin_xyz=origin_xyz)\n",
    "        if m is None or len(m.faces) == 0:\n",
    "            print(f\"âš ï¸  No surface found at {int(lvl*100)}% (try lowering level or increasing n_boot).\")\n",
    "            continue\n",
    "        # color\n",
    "        if colors.get(lvl):\n",
    "            m.visual.face_colors = np.tile(np.array(colors[lvl], dtype=np.uint8), (len(m.faces), 1))\n",
    "        tag = label_map.get(lvl, f\"p{int(lvl*100)}\")\n",
    "        out_glb = os.path.join(out_dir, f\"latent_occ_{tag}.glb\")\n",
    "        m.export(out_glb)\n",
    "        print(f\"âœ“ Saved {out_glb}  (faces={len(m.faces)})\")\n",
    "        meshes.append((tag, m))\n",
    "\n",
    "    # ---- combined GLB with all meshes ----\n",
    "    if meshes:\n",
    "        scene = trimesh.Scene()\n",
    "        for tag, m in meshes:\n",
    "            scene.add_geometry(m, node_name=tag)\n",
    "        combo_path = os.path.join(out_dir, \"latent_occ_all.glb\")\n",
    "        scene.export(combo_path)\n",
    "        print(f\"âœ“ Saved layered GLB: {combo_path}\")\n",
    "\n",
    "    print(\"Done.\")\n",
    "    return prob_zyx, meta\n",
    "\n",
    "# -------------------------- RUN --------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    run_latent_occupancy(csv=csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44f9acf1-a815-4263-826d-0a609bb5d6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== GLB Viewer (Plotly + Trimesh) ====\n",
    "# pip install trimesh plotly\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path\n",
    "\n",
    "def _mesh_to_traces(mesh, name=None, opacity=1.0, showlegend=True):\n",
    "    \"\"\"\n",
    "    Convert a single Trimesh Trimesh() to a Plotly Mesh3d trace.\n",
    "    \"\"\"\n",
    "    v = mesh.vertices\n",
    "    f = mesh.faces\n",
    "    trace = go.Mesh3d(\n",
    "        x=v[:,0], y=v[:,1], z=v[:,2],\n",
    "        i=f[:,0], j=f[:,1], k=f[:,2],\n",
    "        name=name or \"mesh\",\n",
    "        opacity=opacity,\n",
    "        flatshading=True,\n",
    "        showscale=False,\n",
    "        lighting=dict(ambient=0.35, diffuse=0.7, specular=0.2, roughness=0.7, fresnel=0.2),\n",
    "        lightposition=dict(x=1, y=1, z=1),\n",
    "        hoverinfo=\"skip\",\n",
    "        showlegend=showlegend\n",
    "    )\n",
    "    return trace\n",
    "\n",
    "def _scene_to_traces(scene, base_name, default_opacity=1.0):\n",
    "    \"\"\"\n",
    "    Convert a Trimesh Scene() to Plotly traces using world-space meshes.\n",
    "    Uses scene.dump(concatenate=False) so all node transforms are applied.\n",
    "    \"\"\"\n",
    "    traces = []\n",
    "    try:\n",
    "        # Returns a list of Trimesh objects with transforms already applied\n",
    "        meshes_world = scene.dump(concatenate=False)\n",
    "    except Exception:\n",
    "        # Fallback: apply transforms manually\n",
    "        meshes_world = []\n",
    "        for geom_name, mesh in scene.geometry.items():\n",
    "            try:\n",
    "                T = scene.graph.get_transform(geom_name)  # to world\n",
    "            except Exception:\n",
    "                T = np.eye(4)\n",
    "            m = mesh.copy()\n",
    "            m.apply_transform(T)\n",
    "            meshes_world.append(m)\n",
    "\n",
    "    for idx, tm in enumerate(meshes_world):\n",
    "        traces.append(_mesh_to_traces(tm, name=f\"{base_name}:{idx}\", opacity=default_opacity))\n",
    "    return traces\n",
    "\n",
    "\n",
    "def show_glbs(glb_paths, opacities=None, titles=None):\n",
    "    \"\"\"\n",
    "    Show one or more GLB files in a single interactive 3D view.\n",
    "    - glb_paths: list of paths (or a single path)\n",
    "    - opacities: list of floats (0-1), optional; defaults to 0.7 for all but last, 1.0 for last\n",
    "    - titles: legend labels per file, optional\n",
    "    \"\"\"\n",
    "    if isinstance(glb_paths, (str, Path)):\n",
    "        glb_paths = [glb_paths]\n",
    "    glb_paths = [Path(p) for p in glb_paths]\n",
    "\n",
    "    if titles is None:\n",
    "        titles = [p.stem for p in glb_paths]\n",
    "    if opacities is None:\n",
    "        opacities = [0.7]*max(0, len(glb_paths)-1) + ([1.0] if len(glb_paths) else [])\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for p, alpha, title in zip(glb_paths, opacities, titles):\n",
    "        # Force scene load, because a GLB may contain multiple nodes\n",
    "        scene = trimesh.load(p.as_posix(), force='scene')\n",
    "        if isinstance(scene, trimesh.Scene):\n",
    "            traces = _scene_to_traces(scene, base_name=title, default_opacity=alpha)\n",
    "        else:\n",
    "            # sometimes a single mesh comes back\n",
    "            traces = [_mesh_to_traces(scene, name=title, opacity=alpha)]\n",
    "        for t in traces:\n",
    "            fig.add_trace(t)\n",
    "\n",
    "    # Aesthetics: turn off axes, set equal aspect, nice camera\n",
    "    fig.update_scenes(\n",
    "        xaxis_visible=False, yaxis_visible=False, zaxis_visible=False,\n",
    "        aspectmode=\"data\"\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=\"GLB Preview\",\n",
    "        scene_camera=dict(eye=dict(x=1.6, y=1.6, z=1.2)),\n",
    "        legend=dict(itemsizing=\"constant\"),\n",
    "        margin=dict(l=0, r=0, t=30, b=0),\n",
    "    )\n",
    "\n",
    "    # fig.show()\n",
    "    return fig\n",
    "\n",
    "# ------------------ Examples ------------------\n",
    "# 1) View one file:\n",
    "# show_glbs(\"data/green_monkey/va_testing/out_latent_occ/latent_occ_all.glb\")\n",
    "\n",
    "# 2) View multiple surfaces together with different opacities:\n",
    "# show_glbs([\n",
    "#     \"data/green_monkey/va_testing/out_latent_occ/latent_occ_p60.glb\",\n",
    "#     \"data/green_monkey/va_testing/out_latent_occ/latent_occ_p80.glb\",\n",
    "#     \"data/green_monkey/va_testing/out_latent_occ/latent_occ_p95.glb\",\n",
    "# ], opacities=[0.35, 0.55, 0.9], titles=[\"p60\",\"p80\",\"p95\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b13a8d9-2c4b-4688-9333-79ce5f894805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === One-shot viewer: shells (GLB) + raw gene points (Plotly) ===\n",
    "# pip install trimesh plotly pandas\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import trimesh\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path\n",
    "\n",
    "def _mesh_traces_from_trimesh(mesh, name, opacity=1.0, color=None, wireframe=False, wire_width=1):\n",
    "    v = mesh.vertices\n",
    "    f = mesh.faces\n",
    "    traces = [\n",
    "        go.Mesh3d(\n",
    "            x=v[:,0], y=v[:,1], z=v[:,2],\n",
    "            i=f[:,0], j=f[:,1], k=f[:,2],\n",
    "            name=name, opacity=opacity, color=color,\n",
    "            flatshading=True, showscale=False,\n",
    "            lighting=dict(ambient=0.35, diffuse=0.7, specular=0.2, roughness=0.7, fresnel=0.2),\n",
    "            lightposition=dict(x=1, y=1, z=1),\n",
    "            hoverinfo=\"skip\", showlegend=True\n",
    "        )\n",
    "    ]\n",
    "    if wireframe:\n",
    "        # unique undirected edges\n",
    "        edges = np.vstack([f[:,[0,1]], f[:,[1,2]], f[:,[2,0]]])\n",
    "        edges = np.sort(edges, axis=1)\n",
    "        edges = np.unique(edges, axis=0)\n",
    "        # NaN separators to draw many segments in one trace\n",
    "        x = np.empty(edges.shape[0]*3); x[:] = np.nan\n",
    "        y = x.copy(); z = x.copy()\n",
    "        x[0::3] = v[edges[:,0],0]; x[1::3] = v[edges[:,1],0]\n",
    "        y[0::3] = v[edges[:,0],1]; y[1::3] = v[edges[:,1],1]\n",
    "        z[0::3] = v[edges[:,0],2]; z[1::3] = v[edges[:,1],2]\n",
    "        traces.append(go.Scatter3d(\n",
    "            x=x, y=y, z=z, mode=\"lines\",\n",
    "            line=dict(width=wire_width), name=name+\" (edges)\",\n",
    "            hoverinfo=\"skip\", showlegend=False\n",
    "        ))\n",
    "    return traces\n",
    "\n",
    "def _scene_meshes(scene):\n",
    "    \"\"\"Return a list of world-space Trimesh objects from a Trimesh scene or mesh.\"\"\"\n",
    "    if isinstance(scene, trimesh.Scene):\n",
    "        try:\n",
    "            return scene.dump(concatenate=False)\n",
    "        except Exception:\n",
    "            # fallback: apply transforms manually\n",
    "            meshes = []\n",
    "            for geom_name, mesh in scene.geometry.items():\n",
    "                T = scene.graph.get_transform(geom_name)\n",
    "                m = mesh.copy(); m.apply_transform(T)\n",
    "                meshes.append(m)\n",
    "            return meshes\n",
    "    else:\n",
    "        return [scene]\n",
    "\n",
    "def _load_gene_points(csv_path, cols=(\"middle_x\",\"middle_y\",\"middle_z\")):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    pts = df[list(cols)].dropna().values.astype(np.float32)\n",
    "    return pts\n",
    "\n",
    "def show_shells_and_points(\n",
    "    shell_paths,                      # list[str|Path] e.g. [p60.glb, p80.glb, p95.glb]\n",
    "    shell_titles=None,                # [\"p60\",\"p80\",\"p95\"]\n",
    "    shell_colors=None,                # [\"#9db4ff\",\"#ffb085\",\"#2e8b57\"]\n",
    "    shell_opacities=None,             # [0.30, 0.55, 0.90]\n",
    "    wireframe=True, wire_width=1,\n",
    "    csv_path=None,                    # points CSV (optional)\n",
    "    point_size=2, point_color=\"black\", point_opacity=0.45, subsample=None,\n",
    "    camera_eye=(1.6,1.6,1.2),\n",
    "    show=True\n",
    "):\n",
    "    # Normalize inputs\n",
    "    shell_paths = [Path(p) for p in (shell_paths if isinstance(shell_paths, (list, tuple)) else [shell_paths])]\n",
    "    n = len(shell_paths)\n",
    "    if shell_titles is None:   shell_titles = [p.stem for p in shell_paths]\n",
    "    if shell_colors is None:   shell_colors = [None]*n\n",
    "    if shell_opacities is None:\n",
    "        shell_opacities = [0.7]*max(0, n-1) + ([1.0] if n else [])\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add shells\n",
    "    for p, title, color, alpha in zip(shell_paths, shell_titles, shell_colors, shell_opacities):\n",
    "        scene = trimesh.load(p.as_posix(), force='scene')\n",
    "        for idx, mesh in enumerate(_scene_meshes(scene)):\n",
    "            for tr in _mesh_traces_from_trimesh(\n",
    "                mesh, name=f\"{title}\" if n==1 else f\"{title}:{idx}\",\n",
    "                opacity=alpha, color=color, wireframe=wireframe, wire_width=wire_width\n",
    "            ):\n",
    "                fig.add_trace(tr)\n",
    "\n",
    "    # Add points (optional)\n",
    "    if csv_path is not None:\n",
    "        pts = _load_gene_points(csv_path)\n",
    "        if subsample is not None and subsample < len(pts):\n",
    "            idx = np.random.choice(len(pts), subsample, replace=False)\n",
    "            pts = pts[idx]\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=pts[:,0], y=pts[:,1], z=pts[:,2],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=point_size, opacity=point_opacity, color=point_color),\n",
    "            name=\"genes\", hoverinfo=\"skip\", showlegend=True\n",
    "        ))\n",
    "\n",
    "    # Layout\n",
    "    fig.update_scenes(xaxis_visible=False, yaxis_visible=False, zaxis_visible=False, aspectmode=\"data\")\n",
    "    fig.update_layout(\n",
    "        title=\"Genes over Latent Occupancy Shells\" if csv_path else \"Latent Occupancy Shells\",\n",
    "        scene_camera=dict(eye=dict(x=camera_eye[0], y=camera_eye[1], z=camera_eye[2])),\n",
    "        legend=dict(itemsizing=\"constant\"),\n",
    "        margin=dict(l=0, r=0, t=30, b=0),\n",
    "    )\n",
    "    if show:\n",
    "        fig.show()\n",
    "        return\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "csv_path = \"data/green_monkey/all_structure_files/chr1/12hrs/vacv/structure_12hrs_vacv_gene_info.csv\"\n",
    "shells = [\n",
    "    \"data/green_monkey/va_testing/out_latent_occ/latent_occ_p60.glb\",\n",
    "    \"data/green_monkey/va_testing/out_latent_occ/latent_occ_p80.glb\",\n",
    "    \"data/green_monkey/va_testing/out_latent_occ/latent_occ_p95.glb\",\n",
    "]\n",
    "\n",
    "# show_shells_and_points(\n",
    "#     shells,\n",
    "#     shell_titles=[\"p60\",\"p80\",\"p95\"],\n",
    "#     shell_colors=[\"#9db4ff\", \"#ffb085\", \"#2e8b57\"],\n",
    "#     shell_opacities=[0.30, 0.55, 0.90],\n",
    "#     wireframe=False,              # ðŸ”¹ disables edge overlays\n",
    "#     csv_path=csv_path,\n",
    "#     point_size=2, point_color=\"black\", point_opacity=0.45,\n",
    "#     subsample=None,\n",
    "#     camera_eye=(1.6,1.6,1.2),\n",
    "#     show=True\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407a5bf1-c363-4aa2-adf3-8d959564eac1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
