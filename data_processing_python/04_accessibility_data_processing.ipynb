{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3770d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bd16e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before_accessible_file_path = 'data/accessibility/raw-data/2803_017_autosomes_treat_pileup_in_chr.bdg'\n",
    "before_accessible_file_path = 'data/MRC5/accessibility_raw/MRC5_229E_48hr_Mock_ATACseq_merged_reads_in_consensus_peaks_RPKM.bed'\n",
    "\n",
    "# after_accessible_file_path = 'data/accessibility/raw-data/2803_017_autosomes_treat_pileup_in_chr.bdg'\n",
    "after_accessible_file_path = 'data/MRC5/accessibility_raw/MRC5_229E_48hr_229E_ATACseq_merged_reads_in_consensus_peaks_RPKM.bed'\n",
    "# after_path = 'data/dataroot/products/eda-xwtafb42/section'\n",
    "\n",
    "before_path = 'data/MRC5/processed/MRC5/mock'\n",
    "after_path = 'data/MRC5/processed/MRC5/229E'\n",
    "time_hr = '48hr'\n",
    "resolution = '250000'\n",
    "structure_file_name = 'structure-with-id0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6989a12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatePosition(pointA, pointB, percent):\n",
    "    # Calculate the differences in coordinates\n",
    "    delta_x = pointB[0] - pointA[0]\n",
    "    delta_y = pointB[1] - pointA[1]\n",
    "    delta_z = pointB[2] - pointA[2]\n",
    "\n",
    "    # Calculate % of the differences\n",
    "    dif_x = (percent / 100) * delta_x\n",
    "    dif_y = (percent / 100) * delta_y\n",
    "    dif_z = (percent / 100) * delta_z\n",
    "\n",
    "    # Calculate the coordinates of the point at % along the line\n",
    "    x_pos = pointA[0] + dif_x\n",
    "    y_pos = pointA[1] + dif_y\n",
    "    z_pos = pointA[2] + dif_z\n",
    "    \n",
    "    return [x_pos, y_pos, z_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5686028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(df, df_acc, resolution):   \n",
    "    \n",
    "    #deep copy\n",
    "    acc_df = df_acc.copy(deep=True)\n",
    "    \n",
    "    #values to store\n",
    "    start_ids = []\n",
    "    end_ids = []\n",
    "    start_pos = []\n",
    "    start_x = []\n",
    "    start_y = []\n",
    "    start_z = []\n",
    "    end_pos = []\n",
    "    end_x = []\n",
    "    end_y = []\n",
    "    end_z = []\n",
    "    start_percent = []\n",
    "    end_percent = []\n",
    "    middle = []\n",
    "    middle_percent = []\n",
    "    middle_pos = []\n",
    "    middle_x = []\n",
    "    middle_y = []\n",
    "    middle_z = []\n",
    "    \n",
    "    #iterate over the gene data frame\n",
    "    for index, row in acc_df.iterrows():\n",
    "        #get the start and end position\n",
    "        start = row['start']\n",
    "        end = row['end']\n",
    "        \n",
    "        #find the mid position\n",
    "        mid = int((start + end) / 2)\n",
    "        middle.append(mid)\n",
    "\n",
    "        # Calculate the ID range that encompasses the start and end\n",
    "        start_id = (start / resolution)\n",
    "        end_id = (end / resolution)\n",
    "\n",
    "        start_id_int = int(start_id)\n",
    "        end_id_int = int(end_id) + 1\n",
    "\n",
    "        start_ids.append(start_id_int)\n",
    "        end_ids.append(end_id_int)\n",
    "        \n",
    "        # find the percentage of where the mid point is located\n",
    "        m_percent = ((mid - (start_id_int * resolution)) / ((end_id_int * resolution) - (start_id_int * resolution))) * 100\n",
    "        s_percent = m_percent = ((start - (start_id_int * resolution)) / ((end_id_int * resolution) - (start_id_int * resolution))) * 100\n",
    "        e_percent = m_percent = ((end - (start_id_int * resolution)) / ((end_id_int * resolution) - (start_id_int * resolution))) * 100\n",
    "        \n",
    "        middle_percent.append(m_percent)\n",
    "        start_percent.append(s_percent)\n",
    "        end_percent.append(e_percent)\n",
    "\n",
    "\n",
    "#         print(start_id, end_id, start_id_int,end_id_int, len(df))\n",
    "\n",
    "        #getting the coordinates of the start and end beads that encompasses the gene\n",
    "        pointA = 0\n",
    "        pointB = 0\n",
    "        \n",
    "        # Check if start_id and end_id are within the bounds of df_structure\n",
    "        if (start_id_int <= len(df) - 1) and (end_id_int <= len(df) - 1):\n",
    "            \n",
    "#                         print(start_id_int, end_id_int, len(df))\n",
    "            start_row = df[df['id'] == start_id_int]\n",
    "            end_row = df[df['id'] == end_id_int]\n",
    "#             print(start_id_int, end_id_int, len(df))\n",
    "            # Extract x, y, z values if rows are found\n",
    "            if not start_row.empty:\n",
    "                pointA = [start_row.iloc[0]['x'], start_row.iloc[0]['y'], start_row.iloc[0]['z']]\n",
    "#                 start_pos.append(pointA)\n",
    "            if not end_row.empty:\n",
    "                pointB = [end_row.iloc[0]['x'], end_row.iloc[0]['y'], end_row.iloc[0]['z']]\n",
    "#                 end_pos.append(pointB)\n",
    "        else:\n",
    "            \n",
    "#             start_pos.append(None)\n",
    "#             end_pos.append(None)\n",
    "                                \n",
    "            pointA = None\n",
    "            pointB = None\n",
    "            \n",
    "#         print(pointA, pointB)\n",
    "            \n",
    "        #calcualate the coords of the mid point of the gene \n",
    "        # using parametric equation\n",
    "        # for two points P1, P2\n",
    "        # The parametric equation of the line passing through these two points can be written as:\n",
    "        # P(t) = P1 + t. (P2- P1) where t is the percentage value (0-1)\n",
    "        if pointA is not None and pointB is not None:\n",
    "            \n",
    "#             print('not none')\n",
    "            sp = calculatePosition(pointA, pointB, s_percent)\n",
    "            mp = calculatePosition(pointA, pointB, m_percent)\n",
    "            ep = calculatePosition(pointA, pointB, e_percent)        \n",
    "            \n",
    "            start_pos.append(sp)\n",
    "            middle_pos.append(mp)\n",
    "            end_pos.append(ep)\n",
    "            \n",
    "            start_x.append(sp[0])\n",
    "            start_y.append(sp[1])\n",
    "            start_z.append(sp[2])\n",
    "            end_x.append(ep[0])\n",
    "            end_y.append(ep[1])\n",
    "            end_z.append(ep[2])\n",
    "            middle_x.append(mp[0])\n",
    "            middle_y.append(mp[1])\n",
    "            middle_z.append(mp[2])\n",
    "            \n",
    "        else:\n",
    "            start_pos.append(None)\n",
    "            end_pos.append(None)\n",
    "            middle_pos.append(None)\n",
    "            start_x.append(None)\n",
    "            start_y.append(None)\n",
    "            start_z.append(None)\n",
    "            end_x.append(None)\n",
    "            end_y.append(None)\n",
    "            end_z.append(None)\n",
    "            middle_x.append(None)\n",
    "            middle_y.append(None)\n",
    "            middle_z.append(None)\n",
    "            \n",
    "\n",
    "\n",
    "    acc_df['start_id'] = start_ids\n",
    "    acc_df['end_id'] = end_ids\n",
    "    acc_df['start_pos'] = start_pos\n",
    "    acc_df['start_x'] = start_x\n",
    "    acc_df['start_y'] = start_y\n",
    "    acc_df['start_z'] = start_z\n",
    "    acc_df['end_pos'] = end_pos\n",
    "    acc_df['end_x'] = end_x\n",
    "    acc_df['end_y'] = end_y\n",
    "    acc_df['end_z'] = end_z\n",
    "    acc_df['middle'] = middle\n",
    "    acc_df['middle_percent'] = middle_percent\n",
    "    acc_df['middle_pos'] = middle_pos\n",
    "    acc_df['middle_x'] = middle_x\n",
    "    acc_df['middle_y'] = middle_y\n",
    "    acc_df['middle_z'] = middle_z\n",
    "                \n",
    "    print(\"calculation done\")       \n",
    "    return acc_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4362886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accessibility_data_coord_extract(acc_file_path, atom_file_path, hour, resolution, structure_file_name, res):  \n",
    "    # Detect the delimiter (assuming file is either tab-separated or space-separated)\n",
    "    with open(acc_file_path, 'r') as file:\n",
    "        first_line = file.readline().strip()\n",
    "        if '\\t' in first_line:\n",
    "            print('tab')\n",
    "            delimiter = '\\t'\n",
    "        elif ' ' in first_line:\n",
    "            print('space')\n",
    "            delimiter = ' '\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported delimiter. The file must be tab or space separated.\")\n",
    "    \n",
    "    # Read the file without treating any row as header\n",
    "    temp_df = pd.read_csv(acc_file_path, sep=delimiter, header=None, nrows=1)\n",
    "    \n",
    "    # Check if the first row contains header-like values\n",
    "    # Adjust the condition based on what constitutes a header in your files\n",
    "    if temp_df.iloc[0].apply(lambda x: isinstance(x, str)).all():\n",
    "        # The first row is a header\n",
    "        acc = pd.read_csv(acc_file_path, sep=delimiter, header=0)\n",
    "    else:\n",
    "        # The first row is data\n",
    "        acc = pd.read_csv(acc_file_path, sep=delimiter, header=None)\n",
    "        \n",
    "#     print(acc.head())\n",
    "#     print(len(acc.columns))\n",
    "    \n",
    "    # Assign columns based on the number of columns in the DataFrame\n",
    "    acc.columns = ['chrname', 'start', 'end', 'value']\n",
    "    \n",
    "    chr_folder_path = os.path.join(atom_file_path, hour, resolution)\n",
    "    # iterate through structure files 100kb\n",
    "    for chr_folder_name in os.listdir(chr_folder_path):\n",
    "        \n",
    "        print(\"chr folder name ==== \", chr_folder_name)\n",
    "\n",
    "        # Check if the current item is a directory starting with 'chr'\n",
    "        if os.path.isdir(chr_folder_path) and chr_folder_name.startswith('chr'):        \n",
    "            # Navigate into the chr folder and look for structure-with-tracks.csv\n",
    "#             csv_file_path = os.path.join(chr_folder_path, 'structure', '100kb', 'structure-with-id0.csv')\n",
    "            csv_file_path = os.path.join(chr_folder_path, chr_folder_name, f\"{structure_file_name}.csv\" )\n",
    "            \n",
    "            chr_name = ''.join(filter(str.isdigit, chr_folder_name))  \n",
    "            \n",
    "            #removing the 0 at the first\n",
    "            chr_name = chr_name.lstrip('0')\n",
    "            \n",
    "            print(\"chr_name===\", chr_name)\n",
    "            \n",
    "            filtered_acc = acc[acc['chrname'] == f\"chr{chr_name}\"]\n",
    "            \n",
    "            print(f\"data shape = {filtered_acc.shape}\")\n",
    "            \n",
    "\n",
    "            if os.path.exists(csv_file_path):\n",
    "                df = pd.read_csv(csv_file_path)\n",
    "                \n",
    "                acc_with_position = data_processing(df, filtered_acc, res)\n",
    "                \n",
    "                filtered_acc_with_position = acc_with_position.dropna(subset=['middle_pos'])                \n",
    "                \n",
    "                print(\"acc df length\", len(acc_with_position))\n",
    "                print(\"acc df length without NAN middle_pos\", len(filtered_acc_with_position))\n",
    "            \n",
    "                csv_file_path = os.path.join(chr_folder_path, chr_folder_name, 'accessibility-peaks-only.csv')\n",
    "                filtered_acc_with_position.to_csv(csv_file_path, index=False)\n",
    "                \n",
    "                print(f\"data saved {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b549d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tab\n",
      "chr folder name ====  .DS_Store\n",
      "chr folder name ====  chr10\n",
      "chr_name=== 10\n",
      "data shape = (6927, 4)\n",
      "calculation done\n",
      "acc df length 6927\n",
      "acc df length without NAN middle_pos 6927\n",
      "data saved data/MRC5/processed/MRC5/mock/48hr/250000/chr10/accessibility-peaks-only.csv\n",
      "chr folder name ====  chr17\n",
      "chr_name=== 17\n",
      "data shape = (6488, 4)\n",
      "calculation done\n",
      "acc df length 6488\n",
      "acc df length without NAN middle_pos 6486\n",
      "data saved data/MRC5/processed/MRC5/mock/48hr/250000/chr17/accessibility-peaks-only.csv\n",
      "chr folder name ====  chr21\n",
      "chr_name=== 21\n",
      "data shape = (1826, 4)\n",
      "calculation done\n",
      "acc df length 1826\n",
      "acc df length without NAN middle_pos 1826\n",
      "data saved data/MRC5/processed/MRC5/mock/48hr/250000/chr21/accessibility-peaks-only.csv\n",
      "chr folder name ====  chr19\n",
      "chr_name=== 19\n",
      "data shape = (4442, 4)\n",
      "calculation done\n",
      "acc df length 4442\n",
      "acc df length without NAN middle_pos 4442\n",
      "data saved data/MRC5/processed/MRC5/mock/48hr/250000/chr19/accessibility-peaks-only.csv\n",
      "tab\n",
      "chr folder name ====  .DS_Store\n",
      "chr folder name ====  chr10\n",
      "chr_name=== 10\n",
      "data shape = (6488, 4)\n",
      "calculation done\n",
      "acc df length 6488\n",
      "acc df length without NAN middle_pos 6487\n",
      "data saved data/MRC5/processed/MRC5/229E/48hr/250000/chr10/accessibility-peaks-only.csv\n",
      "chr folder name ====  chr17\n",
      "chr_name=== 17\n",
      "data shape = (6068, 4)\n",
      "calculation done\n",
      "acc df length 6068\n",
      "acc df length without NAN middle_pos 6068\n",
      "data saved data/MRC5/processed/MRC5/229E/48hr/250000/chr17/accessibility-peaks-only.csv\n",
      "chr folder name ====  chr21\n",
      "chr_name=== 21\n",
      "data shape = (1685, 4)\n",
      "calculation done\n",
      "acc df length 1685\n",
      "acc df length without NAN middle_pos 1685\n",
      "data saved data/MRC5/processed/MRC5/229E/48hr/250000/chr21/accessibility-peaks-only.csv\n",
      "chr folder name ====  chr19\n",
      "chr_name=== 19\n",
      "data shape = (4496, 4)\n",
      "calculation done\n",
      "acc df length 4496\n",
      "acc df length without NAN middle_pos 4496\n",
      "data saved data/MRC5/processed/MRC5/229E/48hr/250000/chr19/accessibility-peaks-only.csv\n"
     ]
    }
   ],
   "source": [
    "accessibility_data_coord_extract(before_accessible_file_path, before_path, time_hr, resolution, structure_file_name, 250000)\n",
    "accessibility_data_coord_extract(after_accessible_file_path, after_path, time_hr, resolution, structure_file_name, 250000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fde861d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>0.03223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>23</td>\n",
       "      <td>26</td>\n",
       "      <td>0.09669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>0.12892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>28</td>\n",
       "      <td>102</td>\n",
       "      <td>0.19338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1    2        3\n",
       "0  chr1   0   18  0.00000\n",
       "1  chr1  18   23  0.03223\n",
       "2  chr1  23   26  0.09669\n",
       "3  chr1  26   28  0.12892\n",
       "4  chr1  28  102  0.19338"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec499e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
